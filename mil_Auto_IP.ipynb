{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "774e18e0",
   "metadata": {},
   "source": [
    "## import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0959b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data_utils\n",
    "import PIL\n",
    "\n",
    "from torchvision.models import resnet50\n",
    "# from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f6fa0",
   "metadata": {},
   "source": [
    "## define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e8d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define parameters\n",
    "BATCH_N = 1\n",
    "EPOCH_N = 500\n",
    "num_of_tiles = 2000\n",
    "\n",
    "MODEL_FILEPATH = \"/gstore/home/lix233/miltest_bs=\" + str(BATCH_N) + \"_numtiles=\" + str(num_of_tiles) + \"_equalization/\"\n",
    "IMAGE_DATAPATH = \"/gstore/scratch/u/jea/HKoeppen_POPLAR_MIL_tiles/\"\n",
    "\n",
    "META_DATA_CSV = \"/gstore/home/lix233/meta_POP.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e6263",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_FILEPATH):\n",
    "    os.mkdir(MODEL_FILEPATH)\n",
    "    \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae00bd0",
   "metadata": {},
   "source": [
    "## read meta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f24dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(META_DATA_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173c4ec3",
   "metadata": {},
   "source": [
    "### gather names of all the tiles under the each folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d53178",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tiles = [each_tile for each_img in os.listdir(IMAGE_DATAPATH)  for each_tile in os.listdir(IMAGE_DATAPATH+each_img)]\n",
    "all_tiles_imgid = [all_tiles[x].split('_')[0] + '_' +(all_tiles[x].split('_')[1]) for x in range(len(all_tiles))]\n",
    "\n",
    "meta_img = pd.DataFrame({\"img_id\": all_tiles_imgid, \n",
    "                         \"tile_ID\": all_tiles})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aa5fbd",
   "metadata": {},
   "source": [
    "### join the two data frame together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba63fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = meta_df.merge(meta_img, how='left', left_on='img_id', right_on='img_id')\n",
    "print(main_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df[~main_df['tile_ID'].isna()]\n",
    "print(main_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = [main_df.reset_index(drop=True), pd.get_dummies(main_df['immunophenotype']).reset_index(drop=True)]\n",
    "main_df = pd.concat(main_df, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6818f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.assign(ISTRAIN = main_df.DATATYPE == \"train\")\n",
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f3ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd58310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each patient and select tiles to use\n",
    "uniq_ids = np.unique(main_df.img_id)\n",
    "for x in uniq_ids:\n",
    "    tmp_df = main_df[main_df.img_id == x].reset_index(drop=True)\n",
    "\n",
    "    if tmp_df.shape[0] < num_of_tiles:\n",
    "        \n",
    "        # copy the tiles until you hit fifty\n",
    "        sel_indx = []\n",
    "        for x in range(np.ceil(num_of_tiles / tmp_df.shape[0]).astype('int')):\n",
    "            sel_indx.extend(list(range(tmp_df.shape[0])))\n",
    "        sel_indx = sel_indx[0:num_of_tiles]\n",
    "\n",
    "        if tmp_df.ISTRAIN[0]:\n",
    "            train_df = train_df.append(tmp_df.loc[sel_indx])\n",
    "        else:\n",
    "            test_df = test_df.append(tmp_df.loc[sel_indx])\n",
    "    \n",
    "    # for patients with a lot of tiles use them multiple times\n",
    "    elif tmp_df.shape[0] > 10000:\n",
    "        \n",
    "        rng = np.random.default_rng(seed)\n",
    "        rnd_indx = rng.permutation(tmp_df.index)\n",
    "\n",
    "        if tmp_df.ISTRAIN[0]:\n",
    "            for x in range(4):\n",
    "                app_df = tmp_df.loc[rnd_indx[x*num_of_tiles:(x+1)*num_of_tiles]]\n",
    "                app_df.tile_ID = app_df.tile_ID + \"_\" + str(x)\n",
    "                train_df = train_df.append(app_df)\n",
    "\n",
    "        else:\n",
    "            for x in range(4):\n",
    "                app_df = tmp_df.loc[rnd_indx[x*num_of_tiles:(x+1)*num_of_tiles]]\n",
    "                app_df.tile_ID = app_df.tile_ID + \"_\" + str(x)\n",
    "                test_df = test_df.append(app_df)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        rng = np.random.default_rng(seed)\n",
    "        rnd_indx = rng.permutation(tmp_df.index)[0:num_of_tiles]\n",
    "\n",
    "        if tmp_df.ISTRAIN[0]:\n",
    "            train_df = train_df.append(tmp_df.loc[rnd_indx])\n",
    "        else:\n",
    "            test_df = test_df.append(tmp_df.loc[rnd_indx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617fb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset indices for each df\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "meta_dict = {\n",
    "    'train': train_df,\n",
    "    'test': test_df,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In the training set there are \" + str(train_df.shape[0] / num_of_tiles) + \" observations\")\n",
    "print(\"From \" + str(len(np.unique(train_df.img_id))) + \" unique patients\")\n",
    "print(\"In the test set there are \" + str(test_df.shape[0] / num_of_tiles) + \" observations\")\n",
    "print(\"From \" + str(len(np.unique(test_df.img_id))) + \" unique patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba02ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff4eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomVerticalFlip(0.5),\n",
    "        # transforms.RandomEqualize(p=1),\n",
    "        # transforms.ColorJitter(brightness=(0.5,1.5),contrast=(1),saturation=(0.5,1.5),hue=(-0.1,0.1)),\n",
    "        transforms.ToTensor()\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        #transforms.RandomEqualize(p=1),\n",
    "        transforms.ToTensor()\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7eba47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd7c879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea1d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileBags(data_utils.Dataset):\n",
    "\n",
    "    def __init__(self, img_path, meta_df, num_tiles, transforms=None):\n",
    "        self.img_path = img_path\n",
    "        self.meta_df = meta_df\n",
    "        self.num_tiles = num_tiles\n",
    "        self.id_list = list(np.unique(self.meta_df['img_id']))\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_subset = self.meta_df['tile_ID'].loc[self.meta_df['img_id'].isin([self.id_list[idx]])].to_list()\n",
    "        image_tiles = []\n",
    "        \n",
    "        for tile in image_subset:\n",
    "\n",
    "            ## read in the tiff format\n",
    "            tile_folder = tile.split('_')[0] + '_' + tile.split('_')[1]\n",
    "            image = PIL.Image.open(self.img_path + tile_folder + '/' + tile)\n",
    "            \n",
    "            if self.transforms is not None:\n",
    "                image = self.transforms(image)   ### (H,W,C) -> (C,H,W)\n",
    "\n",
    "            image_tiles.append(image)\n",
    "        \n",
    "        # (num_tiles, height, width, channel) -> (num_tiles, channel, height, width)\n",
    "        image_tiles = torch.stack(image_tiles, dim=0)\n",
    "        \n",
    "        tab_label = self.meta_df[['Desert', 'Excluded', 'Inflamed']].loc[self.meta_df['img_id'].isin([self.id_list[idx]])].iloc[0]\n",
    "        \n",
    "        return image_tiles, torch.tensor(tab_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e40d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create training and test datasets\n",
    "image_datasets = {x: TileBags(IMAGE_DATAPATH, meta_dict[x], num_of_tiles, transforms=data_transforms[x]) for x in ['train', 'test']}\n",
    "\n",
    "### Create training and test dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_N, shuffle=True, num_workers=0) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e78e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_batch = next(iter(dataloaders_dict['train']))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(np.transpose(one_batch[0][0,333,:], (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709cacba",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_batch = next(iter(dataloaders_dict['train']))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(np.transpose(one_batch[0][0,333,:], (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b42a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc68f984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a54fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f70a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MIL model\n",
    "class MultiResNet(nn.Module):\n",
    "    def __init__(self, num_tiles = num_of_tiles, tab_dropout = 0.0):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        self.L = 2048\n",
    "        self.D = 128\n",
    "        # self.K = 1\n",
    "        self.num_tiles = num_tiles\n",
    "        \n",
    "        # Model for raw images \n",
    "        self.img_model = resnet50(weights = 'ResNet50_Weights.DEFAULT')\n",
    "        \n",
    "        for param in self.img_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Replace the last fully-connected layer with Identity\n",
    "        # Parameters of newly constructed modules have requires_grad=True by default\n",
    "        self.img_model.fc = nn.Identity() #2048\n",
    "\n",
    "        ## attention score\n",
    "        self.img_attention = nn.Sequential(\n",
    "            nn.Linear(2048, self.D),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.D, 1)\n",
    "        )\n",
    "        \n",
    "        # Final Layers Per Modality\n",
    "        self.img_cls = nn.Sequential(\n",
    "            nn.Linear(2048, 3),   # with attention should be self.L*self.K\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## (batch_size, nums_times, C, H, W)\n",
    "        sh = x.shape\n",
    "        x = x.reshape(sh[0] * sh[1], sh[2], sh[3], sh[4])\n",
    "        \n",
    "        self.img_model.eval() ## to reassure the pre-train weights are used\n",
    "        with torch.no_grad():\n",
    "            img_feats_fc = self.img_model(x)\n",
    "\n",
    "        ## (batch_size, nums_tiles, 2048(nfc))\n",
    "        img_feats_fc = img_feats_fc.reshape(sh[0], sh[1], -1)\n",
    "        # print(img_feats_fc.shape)\n",
    "        \n",
    "        ## (batch_size, nums_tiles, 1)\n",
    "        Atten = self.img_attention(img_feats_fc)\n",
    "        # print(Atten.shape)\n",
    "\n",
    "        ## (batch_size, nums_tiles, 1)\n",
    "        Atten = F.softmax(Atten, dim=1)\n",
    "        # print(Atten.shape)\n",
    "\n",
    "        ## (batch_size, 2048(nfc))\n",
    "        MM = torch.sum(img_feats_fc * Atten, dim=1)\n",
    "        # print(MM.shape)\n",
    "\n",
    "        ## (batch_size, num_cls)\n",
    "        img_prob = self.img_cls(MM)\n",
    "\n",
    "        return img_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1800f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e28aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfbf7b8c",
   "metadata": {},
   "source": [
    "### early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if test loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path=None, trace_func=print,\n",
    "                best_score=None, test_loss_min = np.Inf, curr_epoch=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time test loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each test loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: Current working directory\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.epoch = curr_epoch\n",
    "        self.best_score = best_score\n",
    "        self.early_stop = False\n",
    "        self.test_loss_min = test_loss_min\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.fname = ''\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, test_loss, model, optimizer, scheduler):\n",
    "\n",
    "        score = -test_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(test_loss, model, optimizer, scheduler)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(test_loss, model, optimizer, scheduler)\n",
    "            self.counter = 0\n",
    "        self.epoch += 1\n",
    "\n",
    "    def save_checkpoint(self, test_loss, model, optimizer, scheduler):\n",
    "        '''Saves model when test loss decreases.'''\n",
    "\n",
    "        self.trace_func(f'Test loss decreased ({self.test_loss_min:.6f} --> {test_loss:.6f}).  Saving model ...')\n",
    "\n",
    "        if self.path is None:\n",
    "            self.path = os.getcwd()\n",
    "\n",
    "        out_fname = \"model_\" + '%.6f' % test_loss + \"_\" + str(self.epoch) + \".ckpt\"\n",
    "        self.fname = os.path.join(self.path, out_fname)\n",
    "\n",
    "        # update test loss value\n",
    "        self.test_loss_min = test_loss\n",
    "\n",
    "        # save the info we need to resume training if needed\n",
    "        checkpoint_dict = {\n",
    "            'epoch' : self.epoch,\n",
    "            'test_loss_min' : self.test_loss_min,\n",
    "            'state_dict' : model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint_dict, self.fname)\n",
    "\n",
    "        # save a file pointing to best model\n",
    "        with open(self.path + '/best_model.txt', 'w') as f:\n",
    "            f.write(\"%s\\n\" % self.fname)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c5198c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b68921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b39f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c593894",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "\n",
    "    since = time.time()\n",
    "    early_stopping = EarlyStopping(patience=15, delta=1e-6, path=MODEL_FILEPATH)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and test phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, one_batch in enumerate(dataloaders_dict[phase]):\n",
    "\n",
    "                imgs = one_batch[0].to(device)\n",
    "                outcomes = one_batch[1].float().to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(imgs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    loss = criterion(outputs, outcomes)\n",
    "                  \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * outcomes.size(0)\n",
    "                running_corrects += (torch.sum(preds == torch.max(outcomes, 1).indices)).item()\n",
    "\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders_dict[phase])\n",
    "            epoch_acc = running_corrects / len(image_datasets[phase])\n",
    "            \n",
    "            if phase == 'train':\n",
    "                #avg_train_losses.append(epoch_loss)\n",
    "                with open(MODEL_FILEPATH + '/train_loss.txt', 'a') as f:\n",
    "                    f.write(\"%s\\n\" % epoch_loss + \"%s\\n\" % epoch_acc)\n",
    "            else:\n",
    "                #avg_test_losses.append(epoch_loss)\n",
    "                with open(MODEL_FILEPATH + '/test_loss.txt', 'a') as f:\n",
    "                    f.write(\"%s\\n\" % epoch_loss + \"%s\\n\" % epoch_acc)\n",
    "\n",
    "                # Step LR in test phase\n",
    "                scheduler.step(epoch_loss)\n",
    "\n",
    "                # Track Early Stopping in Test Phase\n",
    "                early_stopping(epoch_loss, model, optimizer, scheduler)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best test MSE: {:6f}'.format(early_stopping.test_loss_min))\n",
    "\n",
    "    # load best model weights\n",
    "    best_model_dict = torch.load(early_stopping.fname)\n",
    "    model.load_state_dict(best_model_dict['state_dict'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e03384f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e11d0e1c",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d95854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model uses frozen layers from resnet for feature extraction\n",
    "feature_extract = True\n",
    "\n",
    "model_ft = MultiResNet().to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff730eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e842caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "criterion_ft = nn.CrossEntropyLoss()\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 10 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "# LR on Plateau - reduces LR by 0.1 after 10 epochs\n",
    "plat_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, mode='min', verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac1f0c",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, criterion_ft, optimizer_ft, plat_lr_scheduler, num_epochs=EPOCH_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d723576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06e4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab378928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d14c3cc5",
   "metadata": {},
   "source": [
    "# Predication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66331c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data_utils\n",
    "import PIL\n",
    "\n",
    "from torchvision.models import resnet50\n",
    "from sklearn.metrics import confusion_matrix \n",
    "# from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/gstore/home/lix233/miltest_bs=1_numtiles=2000_wo_coloraug_wo_normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define parameters\n",
    "BATCH_N = 1\n",
    "EPOCH_N = 500\n",
    "num_of_tiles = 2000\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)    \n",
    "\n",
    "\n",
    "class TileBags(data_utils.Dataset):\n",
    "\n",
    "    def __init__(self, img_path, meta_df, num_tiles, transforms=None):\n",
    "        self.img_path = img_path\n",
    "        self.meta_df = meta_df\n",
    "        self.num_tiles = num_tiles\n",
    "        self.id_list = list(np.unique(self.meta_df['img_id']))\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_subset = self.meta_df['tile_ID'].loc[self.meta_df['img_id'].isin([self.id_list[idx]])].to_list()\n",
    "        image_tiles = []\n",
    "\n",
    "        for tile in image_subset:\n",
    "\n",
    "            ## read in the tiff format\n",
    "            tile_folder = tile.split('_')[0] + '_' + tile.split('_')[1]\n",
    "            image = PIL.Image.open(self.img_path + tile_folder + '/' + tile)\n",
    "\n",
    "            if self.transforms is not None:\n",
    "                image = self.transforms(image)   ### (H,W,C) -> (C,H,W)\n",
    "\n",
    "            image_tiles.append(image)\n",
    "\n",
    "        # (num_tiles, height, width, channel) -> (num_tiles, channel, height, width)\n",
    "        image_tiles = torch.stack(image_tiles, dim=0)\n",
    "\n",
    "        tab_label = self.meta_df[['Desert', 'Excluded', 'Inflamed']].loc[self.meta_df['img_id'].isin([self.id_list[idx]])].iloc[0]\n",
    "\n",
    "        return image_tiles, torch.tensor(tab_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id_list)\n",
    "    \n",
    "# Define MIL model\n",
    "class MultiResNet(nn.Module):\n",
    "    def __init__(self, num_tiles = num_of_tiles, tab_dropout = 0.0):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        self.L = 2048\n",
    "        self.D = 128\n",
    "        # self.K = 1\n",
    "        self.num_tiles = num_tiles\n",
    "        \n",
    "        # Model for raw images \n",
    "        self.img_model = resnet50(weights = 'ResNet50_Weights.DEFAULT')\n",
    "        \n",
    "        for param in self.img_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Replace the last fully-connected layer with Identity\n",
    "        # Parameters of newly constructed modules have requires_grad=True by default\n",
    "        self.img_model.fc = nn.Identity() #2048\n",
    "\n",
    "        ## attention score\n",
    "        self.img_attention = nn.Sequential(\n",
    "            nn.Linear(2048, self.D),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.D, 1)\n",
    "        )\n",
    "        \n",
    "        # Final Layers Per Modality\n",
    "        self.img_cls = nn.Sequential(\n",
    "            nn.Linear(2048, 3),   # with attention should be self.L*self.K\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## (batch_size, nums_times, C, H, W)\n",
    "        sh = x.shape\n",
    "        x = x.reshape(sh[0] * sh[1], sh[2], sh[3], sh[4])\n",
    "        \n",
    "        self.img_model.eval() ## to reassure the pre-train weights are used\n",
    "        with torch.no_grad():\n",
    "            img_feats_fc = self.img_model(x)\n",
    "\n",
    "        ## (batch_size, nums_tiles, 2048(nfc))\n",
    "        img_feats_fc = img_feats_fc.reshape(sh[0], sh[1], -1)\n",
    "        # print(img_feats_fc.shape)\n",
    "        \n",
    "        ## (batch_size, nums_tiles, 1)\n",
    "        Atten = self.img_attention(img_feats_fc)\n",
    "        # print(Atten.shape)\n",
    "\n",
    "        ## (batch_size, nums_tiles, 1)\n",
    "        Atten = F.softmax(Atten, dim=1)\n",
    "        # print(Atten.shape)\n",
    "\n",
    "        ## (batch_size, 2048(nfc))\n",
    "        MM = torch.sum(img_feats_fc * Atten, dim=1)\n",
    "        # print(MM.shape)\n",
    "\n",
    "        ## (batch_size, num_cls)\n",
    "        img_prob = self.img_cls(MM)\n",
    "\n",
    "        return img_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2220854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model uses frozen layers from resnet for feature extraction\n",
    "feature_extract = True\n",
    "\n",
    "model_ft = MultiResNet().to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "criterion_ft = nn.CrossEntropyLoss()\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 10 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "# LR on Plateau - reduces LR by 0.1 after 10 epochs\n",
    "plat_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, mode='min', verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dcf932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model uses frozen layers from resnet for feature extraction\n",
    "feature_extract = True\n",
    "\n",
    "model_ft = MultiResNet().to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/gstore/home/lix233/miltest_bs=1_numtiles=2000_wo_coloraug_wo_normalization/model_0.897802_31.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['test_loss_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84799961",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epoch)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6376f00",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba5f198b",
   "metadata": {},
   "source": [
    "## test on OAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DATAPATH_test1 = '/gstore/scratch/u/jea/HKoeppen_OAK_MIL_tiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddd6641",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tiles_test1 = [each_tile for each_img in os.listdir(IMAGE_DATAPATH_test1)  for each_tile in os.listdir(IMAGE_DATAPATH_test1+each_img)]\n",
    "all_tiles_imgid_test1 = [all_tiles_test1[x].split('_')[0] + '_' +(all_tiles_test1[x].split('_')[1]) for x in range(len(all_tiles_test1))]\n",
    "\n",
    "meta_img_test1 = pd.DataFrame({\"img_id\": all_tiles_imgid_test1, \n",
    "                         \"tile_ID\": all_tiles_test1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26db7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read meta file\n",
    "meta_df_test1 = pd.read_csv('/gstore/home/lix233/meta_OAK.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "### join two data frame together\n",
    "main_df_test1 = meta_df_test1.merge(meta_img_test1, how='left', left_on='img_id', right_on='img_id')\n",
    "print(main_df_test1.shape)\n",
    "\n",
    "main_df_test1 = main_df_test1[~main_df_test1['tile_ID'].isna()]\n",
    "print(main_df_test1.shape)\n",
    "\n",
    "main_df_test1 = [main_df_test1.reset_index(drop=True), pd.get_dummies(main_df_test1['immunophenotype']).reset_index(drop=True)]\n",
    "main_df_test1 = pd.concat(main_df_test1, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058deb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4617395",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loop through each patient and select tiles to use\n",
    "uniq_ids = np.unique(main_df_test1.img_id)\n",
    "for x in uniq_ids:\n",
    "    tmp_df = main_df_test1[main_df_test1.img_id == x].reset_index(drop=True)\n",
    "\n",
    "    if tmp_df.shape[0] < num_of_tiles:\n",
    "\n",
    "        # copy the tiles until you hit fifty\n",
    "        sel_indx = []\n",
    "        for x in range(np.ceil(num_of_tiles / tmp_df.shape[0]).astype('int')):\n",
    "            sel_indx.extend(list(range(tmp_df.shape[0])))\n",
    "        sel_indx = sel_indx[0:num_of_tiles]\n",
    "\n",
    "        test1_df = test1_df.append(tmp_df.loc[sel_indx])\n",
    "       \n",
    "\n",
    "    # for patients with a lot of tiles use them multiple times\n",
    "    elif tmp_df.shape[0] > 10000:\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        rnd_indx = rng.permutation(tmp_df.index)\n",
    "\n",
    "        for x in range(4):\n",
    "            app_df = tmp_df.loc[rnd_indx[x*num_of_tiles:(x+1)*num_of_tiles]]\n",
    "            app_df.tile_ID = app_df.tile_ID + \"_\" + str(x)\n",
    "            test1_df = test1_df.append(app_df)\n",
    "\n",
    "     \n",
    "\n",
    "    else:\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        rnd_indx = rng.permutation(tmp_df.index)[0:num_of_tiles]\n",
    "\n",
    "        test1_df = test1_df.append(tmp_df.loc[rnd_indx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset indices for test1_df\n",
    "test1_df = test1_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dict = {\n",
    "    'test': test1_df,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de72e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In the test set1 there are \" + str(test1_df.shape[0] / num_of_tiles) + \" observations\")\n",
    "print(\"From \" + str(len(np.unique(test1_df.img_id))) + \" unique patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba60a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        # transforms.RandomEqualize(p=1),\n",
    "        transforms.ToTensor()\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create training and test datasets\n",
    "image_datasets = {x: TileBags(IMAGE_DATAPATH_test1, meta_dict[x], num_of_tiles, transforms=data_transforms[x]) for x in ['test']}\n",
    "\n",
    "### Create training and test dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_N, shuffle=False, num_workers=0) for x in ['test']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da665c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a187a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over data.\n",
    "pred_test1= pd.DataFrame(columns = ['prob_Desert', 'prob_Excluded', 'prob_Inflamed', 'Desert', 'Excluded', 'Inflamed'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, one_batch in enumerate(dataloaders_dict['test']):\n",
    "        imgs = one_batch[0].to(device)\n",
    "        outcomes = one_batch[1].float().to(device)\n",
    "\n",
    "        y_pred = model_ft(imgs)\n",
    "\n",
    "        y_pred_df = pd.DataFrame(y_pred.cpu().data.numpy()); y_pred_df.columns = ['prob_Desert', 'prob_Excluded', 'prob_Inflamed']\n",
    "        outcomes_df = pd.DataFrame(outcomes.cpu().data.numpy()); outcomes_df.columns = ['Desert', 'Excluded', 'Inflamed']\n",
    "        this_batch_pred = pd.concat([y_pred_df, outcomes_df], axis=1)\n",
    "\n",
    "        pred_test1 = pd.concat([pred_test1.reset_index(drop=True), this_batch_pred.reset_index(drop = True)], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e6227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test1.to_csv('MIL_OAK.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3446837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\"ID\":uniq_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc54fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pred_test1.reset_index(drop = True), pd.DataFrame({\"ID\":uniq_ids})], axis=1).to_csv('MIL_OAK_v2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8af3d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3af6e69",
   "metadata": {},
   "source": [
    "## test on IMP130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64570bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data_utils\n",
    "import PIL\n",
    "\n",
    "from torchvision.models import resnet50\n",
    "from sklearn.metrics import confusion_matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f197c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define parameters\n",
    "BATCH_N = 1\n",
    "EPOCH_N = 500\n",
    "num_of_tiles = 2000\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)    \n",
    "\n",
    "\n",
    "class TileBags(data_utils.Dataset):\n",
    "\n",
    "    def __init__(self, img_path, meta_df, num_tiles, transforms=None):\n",
    "        self.img_path = img_path\n",
    "        self.meta_df = meta_df\n",
    "        self.num_tiles = num_tiles\n",
    "        self.id_list = list(np.unique(self.meta_df['img_id']))\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_subset = self.meta_df['tile_ID'].loc[self.meta_df['img_id'].isin([self.id_list[idx]])].to_list()\n",
    "        image_tiles = []\n",
    "\n",
    "        for tile in image_subset:\n",
    "\n",
    "            ## read in the tiff format\n",
    "            tile_folder = tile.split('_')[0]\n",
    "            image = PIL.Image.open(self.img_path + tile_folder + '/' + tile)\n",
    "\n",
    "            if self.transforms is not None:\n",
    "                image = self.transforms(image)   ### (H,W,C) -> (C,H,W)\n",
    "\n",
    "            image_tiles.append(image)\n",
    "\n",
    "        # (num_tiles, height, width, channel) -> (num_tiles, channel, height, width)\n",
    "        image_tiles = torch.stack(image_tiles, dim=0)\n",
    "\n",
    "        tab_label = self.meta_df[['Desert', 'Excluded', 'Inflamed']].loc[self.meta_df['img_id'].isin([self.id_list[idx]])].iloc[0]\n",
    "\n",
    "        return image_tiles, torch.tensor(tab_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id_list)\n",
    "    \n",
    "# Define MIL model\n",
    "class MultiResNet(nn.Module):\n",
    "    def __init__(self, num_tiles = num_of_tiles, tab_dropout = 0.0):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        self.L = 2048\n",
    "        self.D = 128\n",
    "        # self.K = 1\n",
    "        self.num_tiles = num_tiles\n",
    "        \n",
    "        # Model for raw images \n",
    "        self.img_model = resnet50(weights = 'ResNet50_Weights.DEFAULT')\n",
    "        \n",
    "        for param in self.img_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Replace the last fully-connected layer with Identity\n",
    "        # Parameters of newly constructed modules have requires_grad=True by default\n",
    "        self.img_model.fc = nn.Identity() #2048\n",
    "\n",
    "        ## attention score\n",
    "        self.img_attention = nn.Sequential(\n",
    "            nn.Linear(2048, self.D),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.D, 1)\n",
    "        )\n",
    "        \n",
    "        # Final Layers Per Modality\n",
    "        self.img_cls = nn.Sequential(\n",
    "            nn.Linear(2048, 3),   # with attention should be self.L*self.K\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## (batch_size, nums_times, C, H, W)\n",
    "        sh = x.shape\n",
    "        x = x.reshape(sh[0] * sh[1], sh[2], sh[3], sh[4])\n",
    "        \n",
    "        self.img_model.eval() ## to reassure the pre-train weights are used\n",
    "        with torch.no_grad():\n",
    "            img_feats_fc = self.img_model(x)\n",
    "\n",
    "        ## (batch_size, nums_tiles, 2048(nfc))\n",
    "        img_feats_fc = img_feats_fc.reshape(sh[0], sh[1], -1)\n",
    "        # print(img_feats_fc.shape)\n",
    "        \n",
    "        ## (batch_size, nums_tiles, 1)\n",
    "        Atten = self.img_attention(img_feats_fc)\n",
    "        # print(Atten.shape)\n",
    "\n",
    "        ## (batch_size, nums_tiles, 1)\n",
    "        Atten = F.softmax(Atten, dim=1)\n",
    "        # print(Atten.shape)\n",
    "\n",
    "        ## (batch_size, 2048(nfc))\n",
    "        MM = torch.sum(img_feats_fc * Atten, dim=1)\n",
    "        # print(MM.shape)\n",
    "\n",
    "        ## (batch_size, num_cls)\n",
    "        img_prob = self.img_cls(MM)\n",
    "\n",
    "        return img_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2622c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model uses frozen layers from resnet for feature extraction\n",
    "feature_extract = True\n",
    "\n",
    "model_ft = MultiResNet().to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "criterion_ft = nn.CrossEntropyLoss()\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 10 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "# LR on Plateau - reduces LR by 0.1 after 10 epochs\n",
    "plat_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, mode='min', verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model uses frozen layers from resnet for feature extraction\n",
    "feature_extract = True\n",
    "\n",
    "model_ft = MultiResNet().to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/gstore/home/lix233/miltest_bs=1_numtiles=2000_wo_coloraug_wo_normalization/model_0.897802_31.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a077041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f723d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['test_loss_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0456dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epoch)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f7a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a88527",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DATAPATH_test2 = '/gstore/scratch/u/jea/HKoeppen_IMP130_MIL_tiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b117db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tiles_test2 = [each_tile for each_img in os.listdir(IMAGE_DATAPATH_test2)  for each_tile in os.listdir(IMAGE_DATAPATH_test2+each_img)]\n",
    "all_tiles_imgid_test2 = [all_tiles_test2[x].split('_')[0] for x in range(len(all_tiles_test2))]\n",
    "\n",
    "meta_img_test2 = pd.DataFrame({\"img_id\": all_tiles_imgid_test2, \n",
    "                               \"tile_ID\": all_tiles_test2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_test2 = pd.read_csv('/gstore/home/lix233/meta_IMP130.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2b4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "### join two data frame together\n",
    "main_df_test2 = meta_df_test2.merge(meta_img_test2, how='left', left_on='img_id', right_on='img_id')\n",
    "print(main_df_test2.shape)\n",
    "\n",
    "main_df_test2 = main_df_test2[~main_df_test2['tile_ID'].isna()]\n",
    "print(main_df_test2.shape)\n",
    "\n",
    "main_df_test2 = [main_df_test2.reset_index(drop=True), pd.get_dummies(main_df_test2['immunophenotype']).reset_index(drop=True)]\n",
    "main_df_test2 = pd.concat(main_df_test2, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55249f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f5bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fac581",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loop through each patient and select tiles to use\n",
    "uniq_ids = np.unique(main_df_test2.img_id)\n",
    "for x in uniq_ids:\n",
    "    tmp_df = main_df_test2[main_df_test2.img_id == x].reset_index(drop=True)\n",
    "\n",
    "    if tmp_df.shape[0] < num_of_tiles:\n",
    "\n",
    "        # copy the tiles until you hit fifty\n",
    "        sel_indx = []\n",
    "        for x in range(np.ceil(num_of_tiles / tmp_df.shape[0]).astype('int')):\n",
    "            sel_indx.extend(list(range(tmp_df.shape[0])))\n",
    "        sel_indx = sel_indx[0:num_of_tiles]\n",
    "\n",
    "        test2_df = test2_df.append(tmp_df.loc[sel_indx])\n",
    "       \n",
    "\n",
    "    # for patients with a lot of tiles use them multiple times\n",
    "    elif tmp_df.shape[0] > 10000:\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        rnd_indx = rng.permutation(tmp_df.index)\n",
    "\n",
    "        for x in range(4):\n",
    "            app_df = tmp_df.loc[rnd_indx[x*num_of_tiles:(x+1)*num_of_tiles]]\n",
    "            app_df.tile_ID = app_df.tile_ID + \"_\" + str(x)\n",
    "            test2_df = test2_df.append(app_df)\n",
    "\n",
    "     \n",
    "\n",
    "    else:\n",
    "\n",
    "        rng = np.random.default_rng(seed)\n",
    "        rnd_indx = rng.permutation(tmp_df.index)[0:num_of_tiles]\n",
    "\n",
    "        test2_df = test2_df.append(tmp_df.loc[rnd_indx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140fa7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset indices for test2_df\n",
    "test2_df = test2_df.reset_index(drop=True)\n",
    "\n",
    "meta_dict = {\n",
    "    'test': test2_df,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f83278",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In the test set2 there are \" + str(test2_df.shape[0] / num_of_tiles) + \" observations\")\n",
    "print(\"From \" + str(len(np.unique(test2_df.img_id))) + \" unique patients\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dfe8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        # transforms.RandomEqualize(p=1),\n",
    "        transforms.ToTensor()\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dece5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create training and test datasets\n",
    "image_datasets = {x: TileBags(IMAGE_DATAPATH_test2, meta_dict[x], num_of_tiles, transforms=data_transforms[x]) for x in ['test']}\n",
    "\n",
    "### Create training and test dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_N, shuffle=False, num_workers=0) for x in ['test']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cce8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4debc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over data.\n",
    "pred_test2= pd.DataFrame(columns = ['prob_Desert', 'prob_Excluded', 'prob_Inflamed', 'Desert', 'Excluded', 'Inflamed'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, one_batch in enumerate(dataloaders_dict['test']):\n",
    "        imgs = one_batch[0].to(device)\n",
    "        outcomes = one_batch[1].float().to(device)\n",
    "\n",
    "        y_pred = model_ft(imgs)\n",
    "\n",
    "        y_pred_df = pd.DataFrame(y_pred.cpu().data.numpy()); y_pred_df.columns = ['prob_Desert', 'prob_Excluded', 'prob_Inflamed']\n",
    "        outcomes_df = pd.DataFrame(outcomes.cpu().data.numpy()); outcomes_df.columns = ['Desert', 'Excluded', 'Inflamed']\n",
    "        this_batch_pred = pd.concat([y_pred_df, outcomes_df], axis=1)\n",
    "\n",
    "        pred_test2 = pd.concat([pred_test2.reset_index(drop=True), this_batch_pred.reset_index(drop = True)], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test2.to_csv('MIL_IMP130.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560dc6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pred_test2.reset_index(drop = True), pd.DataFrame({\"ID\":uniq_ids})], axis=1).to_csv('MIL_IMP130_v2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2473ba67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eabeb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d6d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ViT",
   "language": "python",
   "name": "vit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
